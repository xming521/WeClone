[project]
name = "WeClone"
version = "0.2.24"
description = "One-stop solution for creating your digital avatar from chat history"
authors = [{ name = "xming521" }]
readme = "README.md"
requires-python = ">=3.10,<3.11"

dependencies = [
  "pandas",
  "commentjson",
  "omegaconf",
  "click",
  "tqdm",
  "pydantic==2.10.6",
  "setuptools>=78.1.0",
  "loguru>=0.7.3",
  "tomli; python_version < '3.11'",
  "langchain",
  "openai==1.76.0",
]

[tool.weclone]
# 配置文件的版本号，当配置文件结构或重要默认值发生变化时，应增加此版本号
config_version = "0.2.24"

# 配置文件更新日志
config_changelog = """
[0.2.21] - 2025-05-01 - 增加在线llm清洗数据配置，兼容openai风格接口。
[0.2.22] - 2025-06-05 - 支持图片模态聊天记录微调。
[0.2.24] - 2025-06-19 - add test_model_args and vllm_args。
"""

[dependency-groups]
main = [
  "llamafactory @ git+https://github.com/hiyouga/LLaMA-Factory.git",
  "vllm==0.9.1; platform_system == 'Linux'",
  "torch==2.7.0",
  "transformers==4.52.1",
  "accelerate==1.7.0",
  "triton==3.3.0; platform_system == 'Linux'",
]
sparktts = [
  "einops>=0.8.1",
  "einx>=0.3.0",
  "numpy==1.26.4",
  "omegaconf>=2.3.0",
  "packaging>=24.2",
  "safetensors>=0.5.2",
  "soundfile>=0.12.1",
  "soxr>=0.5.0.post1",
  "torchaudio>=2.6.0",
  "tqdm>=4.66.5",
]

dev = ["pytest", "pytest-order", "pyright", "ruff", "pre-commit"]

[project.scripts]
weclone-cli = "weclone.cli:cli"

[tool.uv]
conflicts = [
  # [{ group = "wx" }, { group = "xcodec" }],
]

[tool.uv.pip]
torch-backend = "auto"

[tool.uv.sources]
torch = [
  { index = "pytorch-cu126", marker = "platform_system == 'Windows'" },
  { index = "pytorch-cu126", marker = "platform_system == 'Linux'" },
]
torchaudio = [
  { index = "pytorch-cu126", marker = "platform_system == 'Windows'" },
  { index = "pytorch-cu126", marker = "platform_system == 'Linux'" },
]
torchvision = [
  { index = "pytorch-cu126", marker = "platform_system == 'Windows'" },
  { index = "pytorch-cu126", marker = "platform_system == 'Linux'" },
]


[[tool.uv.index]]
url = "https://pypi.tuna.tsinghua.edu.cn/simple/"
default = true

[[tool.uv.index]]
name = "pytorch-cu126"
url = "https://download.pytorch.org/whl/cu126"
explicit = true

[tool.setuptools.packages.find]
where = ["."]                      # 表示在项目根目录开始查找
include = ["weclone*"]             # 只包含名为 weclone 的目录及其子包
exclude = ["*tests*", "*archive*"] # 可以选择性排除其他模式，比如测试目录


[tool.pyright]
typeCheckingMode = "basic"
include = ["weclone/data"]
exclude = ["**/archive", "**/tests"]
ignore = ["**/archive"]

reportMissingImports = "error"
reportMissingTypeStubs = false

pythonVersion = "3.10"
pythonPlatform = "Linux"

[tool.ruff]
exclude = [
  "**/archive",
  "**/tests",
  "weclone-audio/src/server未完工",
  "weclone-audio/src/Spark-TTS",
]
line-length = 110

lint.ignore = ["F403", "F405", "E501", "E402"]
lint.select = [
  "F",     # Pyflakes
  "W",     # pycodestyle warnings
  "E",     # pycodestyle errors
  "ASYNC", # flake8-async
  "C4",    # flake8-comprehensions
  "Q",     # flake8-quotes
]
target-version = "py310"

[tool.pytest.ini_options]
addopts = "-x"
