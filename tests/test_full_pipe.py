import functools
import os
import shutil
import subprocess
import sys
import time
from typing import Callable, Optional, Union, cast
from unittest import mock

import pytest

from weclone.utils.config import load_config
from weclone.utils.config_models import DataModality, WCMakeDatasetConfig
from weclone.utils.log import logger

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
PROJECT_ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
DATASET_CSV_DIR = os.path.join(PROJECT_ROOT, "dataset", "csv")
TESTS_DIR = os.path.dirname(__file__)
TEST_DATA_PERSON_DIR = os.path.join(TESTS_DIR, "tests_data", "test_person")


# Backup directories
BACKUP_DIR = os.path.join(PROJECT_ROOT, "test_backup")
MODEL_OUTPUT_BACKUP = os.path.join(BACKUP_DIR, "model_output")
DATASET_CSV_BACKUP = os.path.join(BACKUP_DIR, "dataset_csv")

test_logger = logger.bind()
test_logger.remove()
test_logger.add(
    sys.stderr,
    format="<yellow><b>{message}</b></yellow>",
    colorize=True,
    level="INFO",
)

def get_config_files():
    """è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶"""
    configs_dir = os.path.join(os.path.dirname(__file__), "configs")
    config_files = []
    for file in os.listdir(configs_dir):
        if file.endswith('.jsonc'):
            config_files.append(f"tests/configs/{file}")
    return config_files

def print_test_header(test_name: str, config_file: str = ""):
    line_length = 100
    test_logger.info("\n" + "â”€" * line_length)
    if config_file:
        title = f"  Testing Phase: {test_name} | Config: {os.path.basename(config_file)}  "
    else:
        title = f"  Testing Phase: {test_name}  "
    padding_total = line_length - len(title)
    padding_left = padding_total // 2
    padding_right = padding_total - padding_left
    test_logger.info(" " * padding_left + title + " " * padding_right)
    test_logger.info("â”€" * line_length)

def print_config_header(config_file: str):
    """æ‰“å°é…ç½®æ–‡ä»¶å¼€å§‹æµ‹è¯•çš„å¤´éƒ¨"""
    line_length = 120
    test_logger.info("\n" + "â•" * line_length)
    title = f"  å¼€å§‹æµ‹è¯•é…ç½®æ–‡ä»¶: {os.path.basename(config_file)}  "
    padding_total = line_length - len(title)
    padding_left = padding_total // 2
    padding_right = padding_total - padding_left
    test_logger.info(" " * padding_left + title + " " * padding_right)
    test_logger.info("â•" * line_length)

def setup_data_environment(data_folder_name: str = "test_person"):
    """Setup test data environment for specified folder"""
    test_logger.info(f"ğŸ”§ è®¾ç½® {data_folder_name} æµ‹è¯•æ•°æ®...")
    
    # Create backup directory
    if os.path.exists(BACKUP_DIR):
        shutil.rmtree(BACKUP_DIR)
    os.makedirs(BACKUP_DIR)
    
    # Backup model_output if it exists
    if os.path.exists("model_output"):
        shutil.move("model_output", MODEL_OUTPUT_BACKUP)
        test_logger.info("å·²å¤‡ä»½ model_output ç›®å½•")
    
    # Backup DATASET_CSV_DIR if it exists
    if os.path.exists(DATASET_CSV_DIR):
        shutil.move(DATASET_CSV_DIR, DATASET_CSV_BACKUP)
        test_logger.info("å·²å¤‡ä»½ dataset/csv ç›®å½•")
    
    os.makedirs(DATASET_CSV_DIR)
    
    # Setup specified test data folder
    test_data_source_dir = os.path.join(TESTS_DIR, "tests_data", data_folder_name)
    test_data_csv_dir = os.path.join(DATASET_CSV_DIR, data_folder_name)
    os.makedirs(test_data_csv_dir)

    for item_name in os.listdir(test_data_source_dir):
        source_item_path = os.path.join(test_data_source_dir, item_name)
        if os.path.isfile(source_item_path) and item_name.lower().endswith('.csv'):
            destination_item_path = os.path.join(test_data_csv_dir, item_name)
            shutil.copy2(source_item_path, destination_item_path)
    
    test_logger.info(f"âœ… {data_folder_name} æµ‹è¯•æ•°æ®è®¾ç½®å®Œæˆ")

@pytest.fixture(scope="session", autouse=True)
def setup_test_environment():
    """Setup test environment once for the entire test session"""
    test_logger.info("ğŸ”§ å¼€å§‹è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")
    
    # Use the generic setup function with default test_person data
    setup_data_environment("test_person")
    
    test_logger.info("âœ… æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")
    
    yield  # This is where the testing happens
    
    # Cleanup after all tests are done
    test_logger.info("ğŸ§¹ å¼€å§‹æ¢å¤æµ‹è¯•ç¯å¢ƒ...")
    
    if os.path.exists("model_output"):
        shutil.rmtree("model_output")
    if os.path.exists(DATASET_CSV_DIR):
        shutil.rmtree(DATASET_CSV_DIR)
    
    if os.path.exists(MODEL_OUTPUT_BACKUP):
        shutil.move(MODEL_OUTPUT_BACKUP, "model_output")
    
    if os.path.exists(DATASET_CSV_BACKUP):
        shutil.move(DATASET_CSV_BACKUP, DATASET_CSV_DIR)
    
    if os.path.exists(BACKUP_DIR):
        shutil.rmtree(BACKUP_DIR)
    
    test_logger.info("âœ… æµ‹è¯•ç¯å¢ƒæ¢å¤å®Œæˆ")


def restore_test_env():
    """Manual environment cleanup for direct execution (deprecated for pytest)"""
    test_logger.info("ğŸ§¹ æ‰‹åŠ¨æ¢å¤æµ‹è¯•ç¯å¢ƒ...")
    
    # Remove test directories
    if os.path.exists("model_output"):
        shutil.rmtree("model_output")
    if os.path.exists(DATASET_CSV_DIR):
        shutil.rmtree(DATASET_CSV_DIR)
    
    # Restore original directories if they were backed up
    if os.path.exists(MODEL_OUTPUT_BACKUP):
        shutil.move(MODEL_OUTPUT_BACKUP, "model_output")
        test_logger.info("å·²æ¢å¤ model_output ç›®å½•")
    
    if os.path.exists(DATASET_CSV_BACKUP):
        shutil.move(DATASET_CSV_BACKUP, DATASET_CSV_DIR)
        test_logger.info("å·²æ¢å¤ dataset/csv ç›®å½•")
    
    # Remove backup directory
    if os.path.exists(BACKUP_DIR):
        shutil.rmtree(BACKUP_DIR)
        test_logger.info("å·²æ¸…ç†å¤‡ä»½ç›®å½•")
    
    test_logger.info("âœ… æµ‹è¯•ç¯å¢ƒæ¢å¤å®Œæˆ")

def run_cli_command(command: list[str], config_path: str, timeout: int | None = None, background: bool = False) -> Union[subprocess.CompletedProcess, subprocess.Popen]:
    """Execute a CLI command and return the result.
    
    Args:
        command: List of commands to execute.
        config_path: Path to the configuration file.
        timeout: Timeout in seconds.
        background: Whether to run in the background.
        
    Returns:
        If background=True, returns a Popen object; otherwise, returns a CompletedProcess object.
    """
    env = os.environ.copy()
    env["WECLONE_CONFIG_PATH"] = config_path # Set environment variable

    if background:
        process = subprocess.Popen(
            [sys.executable, "-m", "weclone.cli"] + command,
            stderr=None,
            stdout=None,
            text=True,
            cwd=PROJECT_ROOT_DIR,
            env=env
        )
        time.sleep(2)
        return process
    else:
        process = subprocess.run(
            [sys.executable, "-m", "weclone.cli"] + command,
            stderr=None,
            stdout=None,
            text=True,
            cwd=PROJECT_ROOT_DIR,  # Execute in the project root directory
            timeout=timeout,
            env=env  # Pass the modified environment variables
        )
        return process

def load_config_with_path(config_file: str, config_section: str):
    """ä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡å¹¶åŠ è½½é…ç½®"""
    original_env = os.environ.get("WECLONE_CONFIG_PATH")
    os.environ["WECLONE_CONFIG_PATH"] = config_file
    
    try:
        return load_config(config_section)
    finally:
        # æ¢å¤åŸå§‹ç¯å¢ƒå˜é‡
        if original_env is not None:
            os.environ["WECLONE_CONFIG_PATH"] = original_env
        elif "WECLONE_CONFIG_PATH" in os.environ:
            del os.environ["WECLONE_CONFIG_PATH"]

def run_make_dataset_test(config_file: str):
    """æ‰§è¡Œ make-dataset æµ‹è¯•"""
    print_test_header("make-dataset", config_file)
    
    config: WCMakeDatasetConfig = cast(WCMakeDatasetConfig, load_config_with_path(config_file, "make_dataset"))
    if DataModality.IMAGE in config.include_type:
        #å¤åˆ¶å›¾ç‰‡åˆ°media_dir/iamges
        os.makedirs(config.media_dir, exist_ok=True)
        os.makedirs(os.path.join(config.media_dir, "images"), exist_ok=True)
        for file in os.listdir(os.path.join(PROJECT_ROOT_DIR, "tests", "tests_data", "images")):
            shutil.copy(os.path.join(PROJECT_ROOT_DIR, "tests", "tests_data", "images", file), os.path.join(config.media_dir, "images", file))

    result = run_cli_command(["make-dataset"], config_file)
    assert result.returncode == 0, f"make-dataset command execution failed for config {config_file}"

    # Check if blocked_words filtering is working correctly
    sft_file_path = os.path.join(PROJECT_ROOT_DIR, "dataset", "res_csv", "sft", "sft-my.json")
    with open(sft_file_path, 'r', encoding='utf-8') as f:
        content = f.read()
        if "hh" in content:
            assert False, f"blocked_words filtering failed for config {config_file}: found 'hh' in {sft_file_path}"
    test_logger.info(f"âœ… blocked_words filtering check passed for config {config_file}")
    
    # Check if <image> tags count is correct for Qwen2.5-VL.jsonc config
    if "Qwen2.5-VL.jsonc" in config_file:
        image_count = content.count("<image>")
        assert image_count == 3, f"Expected 3 <image> tags in {sft_file_path} for config {config_file}, but found {image_count}"
        test_logger.info(f"âœ… <image> tags count check passed for config {config_file}: found {image_count} <image> tags")

    

def run_train_sft_test(config_file: str):
    """æ‰§è¡Œ train-sft æµ‹è¯•"""
    print_test_header("train-sft", config_file)
   
    try:
        result = run_cli_command(["train-sft"], config_file) 
        assert result.returncode == 0, f"train-sft command failed or did not fail fast as expected for config {config_file}"
    except subprocess.TimeoutExpired:
        test_logger.info(f"train-sft command terminated due to timeout for config {config_file}, which is acceptable in testing, indicating the command has started execution.")
        pass
    except Exception as e:
        pytest.fail(f"An unexpected error occurred during train-sft command execution for config {config_file}: {e}")

def run_webchat_demo_test(config_file: str):
    """æ‰§è¡Œ webchat-demo æµ‹è¯•"""
    print_test_header("webchat-demo", config_file)
    
    with mock.patch("weclone.eval.web_demo.main") as mock_main:
        mock_main.return_value = None
        try:
            result = run_cli_command(["webchat-demo"], config_file, timeout=20)
            assert result.returncode == 0, f"webchat-demo command execution failed for config {config_file}"
        except subprocess.TimeoutExpired:
            pass

def run_server_test(config_file: str) -> subprocess.Popen:
    """æ‰§è¡Œ server æµ‹è¯•ï¼Œè¿”å›è¿›ç¨‹å¯¹è±¡"""
    print_test_header("server (background)", config_file)
    server_process = cast(subprocess.Popen, run_cli_command(["server"], config_file, background=True))
    test_logger.info("ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨ï¼Œ20ç§’åæ£€æŸ¥çŠ¶æ€...")
    time.sleep(20)
    assert server_process.poll() is None, f"Server startup failed for config {config_file}"
    test_logger.info(f"ä½¿ç”¨é…ç½® {config_file} çš„æœåŠ¡å™¨å·²åœ¨åå°å¯åŠ¨")
    return server_process

def run_test_model_test(config_file: str, server_process: subprocess.Popen):
    """æ‰§è¡Œ test-model æµ‹è¯•å¹¶å…³é—­æœåŠ¡å™¨"""
    print_test_header("test-model", config_file)
    try:
        result = run_cli_command(["test-model"], config_file)
        assert result.returncode == 0, f"test-model command execution failed for config {config_file}"
    finally:
        if server_process is not None and server_process.poll() is None:
            test_logger.info(f"æµ‹è¯•å®Œæˆï¼Œæ­£åœ¨å…³é—­ä½¿ç”¨é…ç½® {config_file} çš„æœåŠ¡å™¨...")
            server_process.terminate()
            server_process.wait(timeout=5)
            if server_process.poll() is None:
                server_process.kill()  # Force kill if the process hasn't terminated
            test_logger.info("æœåŠ¡å™¨å·²å…³é—­")

def clean_model_output():
    """Clean model_output directory before each config test"""
    if os.path.exists("model_output"):
        shutil.rmtree("model_output")

@pytest.mark.parametrize("config_file", get_config_files())
def test_full_pipeline_for_config(config_file):
    """ä¸ºæ¯ä¸ªé…ç½®æ–‡ä»¶å®Œæ•´æ‰§è¡Œæ‰€æœ‰æµ‹è¯•æ­¥éª¤"""
    print_config_header(config_file)
    
    clean_model_output()
    
    server_process = None
    try:
        # æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰æµ‹è¯•æ­¥éª¤
        run_make_dataset_test(config_file)
        run_train_sft_test(config_file)
        run_webchat_demo_test(config_file)
        server_process = run_server_test(config_file)
        run_test_model_test(config_file, server_process)
        
        test_logger.info(f"âœ… é…ç½®æ–‡ä»¶ {os.path.basename(config_file)} çš„æ‰€æœ‰æµ‹è¯•å·²å®Œæˆ")
        
    except Exception as e:
        test_logger.error(f"âŒ é…ç½®æ–‡ä»¶ {os.path.basename(config_file)} æµ‹è¯•å¤±è´¥: {e}")
        if server_process is not None and server_process.poll() is None:
            server_process.terminate()
            server_process.wait(timeout=5)
            if server_process.poll() is None:
                server_process.kill()
        raise

if __name__ == "__main__":
    try:
        # If running directly, you would put your test code here
        pass
    finally:
        restore_test_env()
